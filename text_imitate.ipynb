{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from keras.models import Model, model_from_json\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Input, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "#   from keras.layers import CuDNNLSTM as LSTM\n",
    "#   from keras.layers import CuDNNGRU as GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some configuration\n",
    "MAX_SEQUENCE_LENGTH = 63\n",
    "MAX_VOCAB_SIZE = 4000\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "LATENT_DIM = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "# for line in open('/home/ubuntu/wen/Twitter/Ingested_Tweets/trump_tweets.txt'):\n",
    "for line in open('/home/ubuntu/wen/Twitter/Ingested_Tweets/trump_tweets.csv/part-00000-9519e783-b055-44bf-b20c-54925873e935-c000.csv'):\n",
    "  line = line.rstrip()\n",
    "  if not line:\n",
    "    continue\n",
    "\n",
    "  input_line = '<sos> ' + line\n",
    "  target_line = line + ' <eos>'\n",
    "\n",
    "  input_texts.append(input_line)\n",
    "  target_texts.append(target_line)\n",
    "\n",
    "\n",
    "all_lines = input_texts + target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sentences (strings) into integers\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "tokenizer.fit_on_texts(all_lines)\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "target_sequences = tokenizer.texts_to_sequences(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 63\n"
     ]
    }
   ],
   "source": [
    "# find max seq length\n",
    "max_sequence_length_from_data = max(len(s) for s in input_sequences)\n",
    "print('Max sequence length:', max_sequence_length_from_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9927 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# get word -> integer mapping\n",
    "word2idx = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word2idx))\n",
    "assert('<sos>' in word2idx)\n",
    "assert('<eos>' in word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (5221, 63)\n"
     ]
    }
   ],
   "source": [
    "# pad sequences so that we get a N x T matrix\n",
    "max_sequence_length = min(max_sequence_length_from_data, MAX_SEQUENCE_LENGTH)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_sequence_length, padding='post')\n",
    "print('Shape of data tensor:', input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load in pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('/home/ubuntu/wen/NLP/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx.items():\n",
    "  if i < MAX_VOCAB_SIZE:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # one-hot the targets (can't use sparse cross-entropy)\n",
    "# one_hot_targets = np.zeros((len(input_sequences), max_sequence_length, num_words))\n",
    "# for i, target_sequence in enumerate(target_sequences):\n",
    "#   for t, word in enumerate(target_sequence):\n",
    "#     if word > 0:\n",
    "#       one_hot_targets[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an Embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "#   trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm = model.get_layer('lstm_1').output\n",
    "lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "initial_h = Input(shape=(LATENT_DIM,))\n",
    "initial_c = Input(shape=(LATENT_DIM,))\n",
    "dense = Dense(num_words, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "model = load_model('/home/ubuntu/wen/Twitter/GetOldTweets/trump_tweets_model_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 63)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 63, 50)       200000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 63, 25), (No 7600        embedding_1[0][0]                \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 63, 4000)     104000      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 311,600\n",
      "Trainable params: 311,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.09244964, -0.5509255 , -0.70078194, ..., -1.4140141 ,\n",
       "          0.20953439, -1.4629815 ],\n",
       "        [ 0.17635977,  0.0689066 , -0.35633314, ..., -0.9516743 ,\n",
       "         -0.145526  , -0.3243402 ],\n",
       "        ...,\n",
       "        [ 0.83121043,  0.06326257,  1.0084718 , ...,  1.4751939 ,\n",
       "          0.5868011 ,  0.80888575],\n",
       "        [-0.40411636,  0.95666665,  0.17923869, ...,  0.8277342 ,\n",
       "          0.3717687 , -0.5496339 ],\n",
       "        [ 0.9355164 ,  0.63911474,  0.06472743, ..., -0.6955365 ,\n",
       "         -0.02749704, -2.1178122 ]], dtype=float32),\n",
       " array([[ 0.3073728 ,  0.13198818,  0.15974176, ..., -0.6183193 ,\n",
       "          1.666149  ,  1.0696961 ],\n",
       "        [-0.05603839,  0.30225712,  0.1414418 , ...,  0.14897741,\n",
       "          0.1663367 , -0.68071973],\n",
       "        [ 0.3029023 ,  0.08806106, -0.08740757, ..., -0.05381489,\n",
       "          1.324471  , -0.49656278],\n",
       "        ...,\n",
       "        [-0.21386793, -0.3220795 ,  0.17457408, ...,  1.7742937 ,\n",
       "          1.254042  ,  0.08281366],\n",
       "        [ 0.29956526, -0.0788402 , -0.3568457 , ..., -0.8118953 ,\n",
       "          1.8196481 ,  0.5545538 ],\n",
       "        [ 0.26535222,  0.47267327,  0.01325769, ...,  1.0028961 ,\n",
       "          0.27070272,  2.0673277 ]], dtype=float32),\n",
       " array([[ 4.8525932e-01,  2.0298126e-01,  2.2008799e-01, ...,\n",
       "         -4.3292466e-01,  6.1737341e-01,  1.7358966e-01],\n",
       "        [-1.0865919e-01, -9.4548726e-01, -4.3546477e-01, ...,\n",
       "         -2.8229547e+00, -7.0317161e-01,  3.3393696e-01],\n",
       "        [-7.5328398e-01, -3.4788015e-01, -5.4608530e-01, ...,\n",
       "         -5.4753754e-02,  9.6449876e-01,  6.9759554e-01],\n",
       "        ...,\n",
       "        [ 1.2669151e-01,  3.0503026e-01, -2.0521869e-01, ...,\n",
       "          1.7985995e+00, -7.3198840e-04, -1.0665976e+00],\n",
       "        [-1.4456621e-01, -4.2775410e-01, -2.8025055e-01, ...,\n",
       "         -2.6417840e-01, -1.3524058e+00,  5.8407102e-02],\n",
       "        [ 5.2037263e-01, -1.6689146e-01, -2.0553286e-01, ...,\n",
       "         -1.7969616e-01,  2.2614899e-01, -1.0714544e+00]], dtype=float32),\n",
       " array([ 0.26424307,  0.33872303,  0.27468514,  0.1296361 ,  0.35124734,\n",
       "         0.26933944,  0.34880385,  0.32670024,  0.44146934,  0.35796073,\n",
       "         0.46415868,  0.3318217 ,  0.3607987 ,  0.4720713 ,  0.28797182,\n",
       "         0.40417987,  0.27722234,  0.34640285,  0.35932645,  0.3843727 ,\n",
       "         0.29771245,  0.24853016,  0.39070913,  0.3556745 ,  0.35213423,\n",
       "         1.2923355 ,  1.244791  ,  1.1404358 ,  1.2043785 ,  1.1699735 ,\n",
       "         1.2153519 ,  1.3559746 ,  1.1410005 ,  1.2665819 ,  1.2687984 ,\n",
       "         1.0691998 ,  1.1763407 ,  1.178994  ,  1.2330217 ,  1.1983786 ,\n",
       "         1.2348382 ,  1.2113359 ,  1.1674733 ,  1.3838352 ,  1.2119282 ,\n",
       "         1.2003946 ,  1.1372826 ,  1.3663511 ,  1.1893378 ,  1.1966242 ,\n",
       "         0.24427359, -0.24465671, -0.19937713, -0.20886548,  0.18309972,\n",
       "        -0.23831148, -0.19803548, -0.20576711, -0.2914986 , -0.26297274,\n",
       "         0.14504625, -0.1668604 ,  0.18269457,  0.19690858,  0.20359556,\n",
       "         0.27119112,  0.21665098, -0.2716788 , -0.2946268 , -0.16295289,\n",
       "        -0.25067812,  0.2312694 ,  0.20720868, -0.2522983 , -0.23082928,\n",
       "        -0.15743457,  0.22439969,  0.12971063, -0.09102365,  0.03640141,\n",
       "        -0.09146313,  0.10033125,  0.10376775,  0.46320045,  0.13879482,\n",
       "         0.42536736, -0.40397033,  0.26310626,  0.1572536 , -0.05186983,\n",
       "         0.33053634,  0.02166904,  0.10527921,  0.01132901, -0.0141722 ,\n",
       "         0.08283313,  0.06308774,  0.09955575, -0.02289491,  0.02150289],\n",
       "       dtype=float32),\n",
       " array([[-0.5042608 ,  0.14898972,  0.71959716, ..., -1.0138385 ,\n",
       "          0.37458125, -0.61360264],\n",
       "        [ 0.5877751 ,  0.45293942, -0.3208819 , ...,  0.98270535,\n",
       "          1.5332952 , -0.41992065],\n",
       "        [ 0.5897173 , -0.49695712, -1.0292032 , ...,  0.16019972,\n",
       "         -0.29893258,  1.1267364 ],\n",
       "        ...,\n",
       "        [-0.5869027 , -0.3976653 ,  1.2729615 , ..., -0.20612003,\n",
       "         -1.6147565 , -1.4038879 ],\n",
       "        [ 0.4367996 , -0.99238926, -0.4740629 , ..., -0.47073078,\n",
       "          0.9273903 ,  0.9158581 ],\n",
       "        [ 0.5367457 , -0.3220786 , -0.5606615 , ...,  0.06609507,\n",
       "          0.835324  , -0.0278485 ]], dtype=float32),\n",
       " array([-0.45895585,  0.4248798 ,  0.37795392, ..., -0.36522964,\n",
       "        -0.01652921, -0.10859235], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_1=model.get_layer('embedding_1').get_weights()\n",
    "lstm_1=model.get_layer('lstm_1').get_weights()\n",
    "dense_1=model.get_layer('dense_1').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sampling model\n",
    "input2 = Input(shape=(1,)) # we'll only input one word at a time\n",
    "x = embedding_layer(input2)\n",
    "x, h, c = lstm(x, initial_state=[initial_h, initial_c]) # now we need states to feed back in\n",
    "output2 = dense(x)\n",
    "sampling_model = Model([input2, initial_h, initial_c], [output2, h, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_model.get_layer('embedding_1').set_weights(embedding_1)\n",
    "sampling_model.get_layer('lstm_1').set_weights(lstm_1)\n",
    "sampling_model.get_layer('dense_1').set_weights(dense_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.09244964, -0.5509255 , -0.70078194, ..., -1.4140141 ,\n",
       "          0.20953439, -1.4629815 ],\n",
       "        [ 0.17635977,  0.0689066 , -0.35633314, ..., -0.9516743 ,\n",
       "         -0.145526  , -0.3243402 ],\n",
       "        ...,\n",
       "        [ 0.83121043,  0.06326257,  1.0084718 , ...,  1.4751939 ,\n",
       "          0.5868011 ,  0.80888575],\n",
       "        [-0.40411636,  0.95666665,  0.17923869, ...,  0.8277342 ,\n",
       "          0.3717687 , -0.5496339 ],\n",
       "        [ 0.9355164 ,  0.63911474,  0.06472743, ..., -0.6955365 ,\n",
       "         -0.02749704, -2.1178122 ]], dtype=float32),\n",
       " array([[ 0.3073728 ,  0.13198818,  0.15974176, ..., -0.6183193 ,\n",
       "          1.666149  ,  1.0696961 ],\n",
       "        [-0.05603839,  0.30225712,  0.1414418 , ...,  0.14897741,\n",
       "          0.1663367 , -0.68071973],\n",
       "        [ 0.3029023 ,  0.08806106, -0.08740757, ..., -0.05381489,\n",
       "          1.324471  , -0.49656278],\n",
       "        ...,\n",
       "        [-0.21386793, -0.3220795 ,  0.17457408, ...,  1.7742937 ,\n",
       "          1.254042  ,  0.08281366],\n",
       "        [ 0.29956526, -0.0788402 , -0.3568457 , ..., -0.8118953 ,\n",
       "          1.8196481 ,  0.5545538 ],\n",
       "        [ 0.26535222,  0.47267327,  0.01325769, ...,  1.0028961 ,\n",
       "          0.27070272,  2.0673277 ]], dtype=float32),\n",
       " array([[ 4.8525932e-01,  2.0298126e-01,  2.2008799e-01, ...,\n",
       "         -4.3292466e-01,  6.1737341e-01,  1.7358966e-01],\n",
       "        [-1.0865919e-01, -9.4548726e-01, -4.3546477e-01, ...,\n",
       "         -2.8229547e+00, -7.0317161e-01,  3.3393696e-01],\n",
       "        [-7.5328398e-01, -3.4788015e-01, -5.4608530e-01, ...,\n",
       "         -5.4753754e-02,  9.6449876e-01,  6.9759554e-01],\n",
       "        ...,\n",
       "        [ 1.2669151e-01,  3.0503026e-01, -2.0521869e-01, ...,\n",
       "          1.7985995e+00, -7.3198840e-04, -1.0665976e+00],\n",
       "        [-1.4456621e-01, -4.2775410e-01, -2.8025055e-01, ...,\n",
       "         -2.6417840e-01, -1.3524058e+00,  5.8407102e-02],\n",
       "        [ 5.2037263e-01, -1.6689146e-01, -2.0553286e-01, ...,\n",
       "         -1.7969616e-01,  2.2614899e-01, -1.0714544e+00]], dtype=float32),\n",
       " array([ 0.26424307,  0.33872303,  0.27468514,  0.1296361 ,  0.35124734,\n",
       "         0.26933944,  0.34880385,  0.32670024,  0.44146934,  0.35796073,\n",
       "         0.46415868,  0.3318217 ,  0.3607987 ,  0.4720713 ,  0.28797182,\n",
       "         0.40417987,  0.27722234,  0.34640285,  0.35932645,  0.3843727 ,\n",
       "         0.29771245,  0.24853016,  0.39070913,  0.3556745 ,  0.35213423,\n",
       "         1.2923355 ,  1.244791  ,  1.1404358 ,  1.2043785 ,  1.1699735 ,\n",
       "         1.2153519 ,  1.3559746 ,  1.1410005 ,  1.2665819 ,  1.2687984 ,\n",
       "         1.0691998 ,  1.1763407 ,  1.178994  ,  1.2330217 ,  1.1983786 ,\n",
       "         1.2348382 ,  1.2113359 ,  1.1674733 ,  1.3838352 ,  1.2119282 ,\n",
       "         1.2003946 ,  1.1372826 ,  1.3663511 ,  1.1893378 ,  1.1966242 ,\n",
       "         0.24427359, -0.24465671, -0.19937713, -0.20886548,  0.18309972,\n",
       "        -0.23831148, -0.19803548, -0.20576711, -0.2914986 , -0.26297274,\n",
       "         0.14504625, -0.1668604 ,  0.18269457,  0.19690858,  0.20359556,\n",
       "         0.27119112,  0.21665098, -0.2716788 , -0.2946268 , -0.16295289,\n",
       "        -0.25067812,  0.2312694 ,  0.20720868, -0.2522983 , -0.23082928,\n",
       "        -0.15743457,  0.22439969,  0.12971063, -0.09102365,  0.03640141,\n",
       "        -0.09146313,  0.10033125,  0.10376775,  0.46320045,  0.13879482,\n",
       "         0.42536736, -0.40397033,  0.26310626,  0.1572536 , -0.05186983,\n",
       "         0.33053634,  0.02166904,  0.10527921,  0.01132901, -0.0141722 ,\n",
       "         0.08283313,  0.06308774,  0.09955575, -0.02289491,  0.02150289],\n",
       "       dtype=float32),\n",
       " array([[-0.5042608 ,  0.14898972,  0.71959716, ..., -1.0138385 ,\n",
       "          0.37458125, -0.61360264],\n",
       "        [ 0.5877751 ,  0.45293942, -0.3208819 , ...,  0.98270535,\n",
       "          1.5332952 , -0.41992065],\n",
       "        [ 0.5897173 , -0.49695712, -1.0292032 , ...,  0.16019972,\n",
       "         -0.29893258,  1.1267364 ],\n",
       "        ...,\n",
       "        [-0.5869027 , -0.3976653 ,  1.2729615 , ..., -0.20612003,\n",
       "         -1.6147565 , -1.4038879 ],\n",
       "        [ 0.4367996 , -0.99238926, -0.4740629 , ..., -0.47073078,\n",
       "          0.9273903 ,  0.9158581 ],\n",
       "        [ 0.5367457 , -0.3220786 , -0.5606615 , ...,  0.06609507,\n",
       "          0.835324  , -0.0278485 ]], dtype=float32),\n",
       " array([-0.45895585,  0.4248798 ,  0.37795392, ..., -0.36522964,\n",
       "        -0.01652921, -0.10859235], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse word2idx dictionary to get back words\n",
    "# during prediction\n",
    "idx2word = {v:k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_line():\n",
    "  # initial inputs\n",
    "  np_input = np.array([[ word2idx['<sos>'] ]])\n",
    "  h = np.zeros((1, LATENT_DIM))\n",
    "  c = np.zeros((1, LATENT_DIM))\n",
    "\n",
    "  # so we know when to quit\n",
    "  eos = word2idx['<eos>']\n",
    "\n",
    "  # store the output here\n",
    "  output_sentence = []\n",
    "\n",
    "  for _ in range(max_sequence_length):\n",
    "    o, h, c = sampling_model.predict([np_input, h, c])\n",
    "\n",
    "    # print(\"o.shape:\", o.shape, o[0,0,:10])\n",
    "    # idx = np.argmax(o[0,0])\n",
    "    probs = o[0,0]\n",
    "    if np.argmax(probs) == 0:\n",
    "      print(\"wtf\")\n",
    "    probs[0] = 0\n",
    "    probs /= probs.sum()\n",
    "    idx = np.random.choice(len(probs), p=probs)\n",
    "    if idx == eos:\n",
    "      break\n",
    "\n",
    "    # accuulate output\n",
    "    output_sentence.append(idx2word.get(idx, '<WTF %s>' % idx))\n",
    "\n",
    "    # make the next input into model\n",
    "    np_input[0,0] = idx\n",
    "\n",
    "  return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so everybody gain on your job and apply loyalty we are making america great country foreign reasons they are negative to negotiate great meetings with president xi of governor and they answered he is no higher deadly new two drug drug dealers back for american post russia has been agreed at the southern border flight to stop being in november the inspector general\n",
      "---generate another? [Y/n]---y\n",
      "to their biggest tax cuts workers and friends\n",
      "---generate another? [Y/n]---y\n",
      "by him take 40 representatives at a joint plants we much and from walter gillespie need working importantly the campaign or business person gave on jobs than anyone others the woodward at despite the russian now beautiful evening at 7 trillion dollars more than possible will have a very big and there asked just a many russians at all being account in we\n",
      "---generate another? [Y/n]---y\n",
      "and the truth see what it is probably never authorized john says tremendous supporter of something and bad and beat houston civilian taxpayer and its they do also roy good very dangerous relationship by your independence i am on the u s dying place and some will be fired for the political process and the swamp was briefed foxandfriends\n",
      "---generate another? [Y/n]---y\n",
      "to highest level and for senate will win now the entire day and potential is tough and vote and owners to win to make a bipartisan etc is fantastic opportunity to all mark court were illegal immigration laws are not used foxandfriends is that i have lost the spirit the to a powerful shows supporting the american men women in north korea total\n",
      "---generate another? [Y/n]---y\n",
      "after contract of the ads\n",
      "---generate another? [Y/n]---y\n",
      "now was honored around the best and best payments to protect many years from the united states and comey ever gillum that this is too onto it works hard to you save rebuild such a tomorrow word i can t get wonderful for for the great of this time that the breaking wealth when we are coming http\n",
      "---generate another? [Y/n]---y\n",
      "first lady melania is tough on the world has been no doubt that judge brett kavanaugh and vote\n",
      "---generate another? [Y/n]---y\n",
      "big trump race i would q ever so proud of the white house\n",
      "---generate another? [Y/n]---y\n",
      "actually going in the usmca it is impossible to do the lake are successful again is successful member of nearly criminal aliens http\n",
      "---generate another? [Y/n]---y\n",
      "i who are this pays billion as many american citizens and me for moments in 8pme increased talks with north korea and good fine\n",
      "---generate another? [Y/n]---y\n",
      "it wasn t me i love you needed this second responders who\n",
      "---generate another? [Y/n]---y\n",
      "thank you new jersey also i can keep the thousand women of this horrible stuff all of the fema day a lobbyist scale the to texas have told the state of the negotiation restore people in mexican\n",
      "---generate another? [Y/n]---y\n",
      "the democrats want to our military and the great of their loyalty to be allowed the taxpayer we should deliver after the world has the people of the most then tremendous law enforcement\n",
      "---generate another? [Y/n]---y\n",
      "my administration and h nelly wants to fight in massive tax cuts we pardon are doing called with the military and unconstitutional tax reform tariff on his rock story\n",
      "---generate another? [Y/n]---y\n",
      "brian kemp in iran 2nd amendment why seem need to tell us more to 9 peter s anymore when all haters go https\n",
      "---generate another? [Y/n]---y\n",
      "needs to the great state will be loser\n",
      "---generate another? [Y/n]---y\n",
      "spying exposed and the farmers will not be done for our military men and could ensure china and angry to the trump campaign know that add this w and foxnews\n",
      "---generate another? [Y/n]---y\n",
      "is a truly fine great healthcare and for course not our 100th minutes by the democrat tight strong and campaign on trade deficit\n"
     ]
    }
   ],
   "source": [
    "# generate a 5 line poem\n",
    "while True:\n",
    "  for _ in range(1):\n",
    "    print(sample_line())\n",
    "\n",
    "  ans = input(\"---generate another? [Y/n]---\")\n",
    "  if ans and ans[0].lower().startswith('n'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
